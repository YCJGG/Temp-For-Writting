

\IEEEraisesectionheading{\section{Introduction}\label{sec:introduction}}

%# p1
{W}{ith} the prevalence of touchscreens in consumer electronics (ranging from portable devices to large home appliance),
 human-machine interactions in free-hand drawings are becoming evermore facilitated and promoted. 
 The input of sketches is a succinct, convenient and efficient means of for visually recording ideas, and can beat hundreds of words in some scenarios. 
 Previous studies range from sketch recognition
  \cite{sketchanet}, sketch-based image retrieval(SBIR) \cite{SaavedraB10,2012sketchhash,Yu2016shoes,SangkloyBHH16,SongYSXH17,EitzHBA10},
  to sketch-image generation. 

%# p2 : 总述sketch research 存在的问题

Despite great progress made, problems concerning sketches are very challenging due to the facts that:(i)Free-hand sketches are inherently abstract and iconic.
For SBIR and sketch-to-image generation, sketch domain and natural image domain are two distinctive domains with heterogeneous feature representations and distributions. The former is characterised by 
sparse black line drawing with white background while the latter consists of dense color pixels. Hence, it is difficult to explore their semantic 
relevance in sufficient detail to bridge the domain gap. For sketch recognition, the highly abstract sketches consist of lines instead of colored pixels, making them lack visual cues.
(ii) Sketches often display a varied levels of abstraction, sophistication and deformation, which is because same objects (maybe without any reference photo) can be drawn in total different styles. 
(iii) Sketch researches lack freely available sketch data. Compared with natural image based research whose million-scale datasets had been accessible for almost a decade, most existing 
sketch-based research can only utilize sub-million level crowd-sourced sketch datasets.

%# p3 ：简述前人的工作和存在的问题
To address above challenges, for SBIR, recent works attempt to employ cross-view learning methods \cite{SaavedraB10,EitzHBA10,LiuSSLS17,SaavedraB15,hu2010,ParuiM14,dalal2005,hu2010_1,Saavedra14,Lowe99}.
These deep models aim to reduce the domain discrepancy by embedding both sketches and natural images into a common space and use the projected features for retrieval.
Concretely, multi-branch deep convolutional neural networks (CNNs) are utilized where each branch corresponds to one domain and the final weight-shared layer embeds them into a common
subspace which is guided by pairwise contrastive loss or triplet ranking loss.
The most critical deficiency in this line of approaches is the difficulty in capturing all the domain-invariant information with focusing only on discriminative losses.
Thus, with the not well-bridged domain gap, these models generalize poorly especially for categories with large variance. 
Besides, the query time of these real-valued methods grows exponentially with the database size and dimensions of sketch/image representations. To this end, Deep Sketch Hashing 
(DSH) \cite{LiuSSLS17} is introduced to replace full-precision sketch/image representations with binary vectors. However, the quantization error introduced 
by the binarization procedure can destroy both domain-invariant information and semantic consistency across domains. 
For sketch recognition, Previous methods generally follow the conventional image recognition paradigm, that is, extracting the deep features of sketches and feeding them to 
a softmax classifier. Nevertheless, due to the difficulty of capturing proper features of sketches and the large domain gap between images and sketches, the net architecture of sketch recognition needs to be specially designed.
\cite{sketchanet} proposed a network named Sketch-a-Net which has a larger kernel size and stride than AlexNet. However, with the lack of available sketch data, the Sketch-a-Net is 
very difficult to be trained without sophisticated and heavy data augmentation.


%#p4 : 简述本文的工作和解决的问题

In this work,our primary goal is to overcome the limitations of the aforementioned methods and provide a practical 
solution to the scalable SBIR and sketch recognition problems.
We propose a Generative Domain-migration Hashing (GDH) method that improves generalization capabilities 
by migrating sketches into the natural image domain, 
where the distribution of migrated sketches is indistinguishable from the distribution of the natural images. Additionally, 
we introduce an end-to-end multi-task learning framework that jointly optimizes 
the cycle consistent migration as well as the hash codes, where the adversarial 
loss and the cycle consistency loss can simultaneously preserve the semantic consistency of the hash codes. 
GDH also integrates cycle attention layers that guide the learning process to focus on the most representative regions.
Besides, sketch recognition can also benefit from the domain-migration strategy. 
The generative model improves ability of generalization by migrating sketches into 
their corresponding natural image domain avoiding sophisticated and heavy data augmentation 
and making the inputs more suitable for the scratch/pretrained image models.
While standard SBIR aims to retrieve natural images that shares identical category 
labels with the query sketch, fine-grained SBIR aims to preserve the intra-category 
instance-level consistency in addition to the category-level consistency. For 
consistency purposes, we refer to standard SBIR as "category-level SBIR" and the 
fine-grained version as "fine-grained SBIR" respectively throughout the paper. 
Since the bidirectional mappings learned in GDH are highly under-constrained 
(\emph{i.e.}, do not require pixel-level alignment \cite{IsolaZZE17} between 
sketches and natural images), GDH can naturally provide an elegant solution 
for preserving the geometrical morphology and detailed instance-level characteristic 
between sketches and natural images. Additionally, a weighted triplet ranking loss is introduced 
to enhance the fine-grained learning based on visual similarities between intra-class instances.
The pipeline of the proposed GDH method for both category-level and fine-grained SBIR tasks
is illustrated in Fig. \ref{fig:overview}. 
Extensive experiments using various large-scale datasets for three tasks (category-level SBIR,
fine-grained SBIR and recognition) demonstrate the consistent, overall superiority
of GDH in terms of memory cost, time cost and retrieval/recognition accuracy. 
The main contributions of this work are as follows:

  \begin{itemize}
  \item 
  
    we propose the first cycle attention generative model GDH for the hashing-based SBIR problem. 
    Compared to existing methods, the generative model fundamentally improves
    generalization capability by migrating sketches into their indistinguishable counterparts 
    in the natural image domain.
  
  \item Guided by an adversarial loss and a cycle consistency loss, 
  the optimized binary hash codes preserve semantic consistency 
  across domains. Furthermore, training GDH does not require pixel-level 
  alignment across domains, and thus enables generalized and practical applications.

  \item 
  GDH shows improved category-level SBIR performance over the state-of-the-art 
  hashing-based SBIR method DSH \cite{LiuSSLS17} by up to $20.5\%$ for the TU-Berlin 
  Extension dataset, and up to $26.4\%$ for the Sketchy dataset. In addition, 
  GDH achieves comparable performance with real-valued fine-grained SBIR methods, while 
  significantly reducing the retrieval time and memory cost with binary codes. 

  \item
  The domain-migration strategy improves sketch recognition performance over
  state-of-the-art method without data augmentation on the TU-Berlin dataset. 
  Meanwhile, it also surpasses human performance in sketch recognition.
  
 \end{itemize}


